{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "broader_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nGzUpUE1XKfr",
        "colab_type": "code",
        "outputId": "fe07b529-0c1b-4f25-d9d8-12381cf2b52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRCiF3GDXTOh",
        "colab_type": "code",
        "outputId": "2e4ea2ea-c991-456a-8bb5-e81b9321d710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3326
        }
      },
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"shakespeare.txt\"\n",
        "f = open(filename)\n",
        "lines = f.readlines()\n",
        "raw_text = \"\"\n",
        "for line in lines:\n",
        "    if lines == '\\n':\n",
        "        continue\n",
        "    try:\n",
        "        int(line)\n",
        "    except ValueError:\n",
        "        raw_text = raw_text + line\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "# create mapping of unique chars to\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 40\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(200, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(800, return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(800))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# define the checkpoint\n",
        "filepath=\"quick-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=101, batch_size=200, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  94595\n",
            "Total Vocab:  38\n",
            "Total Patterns:  94555\n",
            "Epoch 1/101\n",
            "94555/94555 [==============================] - 44s 465us/step - loss: 2.9935\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.99352, saving model to quick-01.hdf5\n",
            "Epoch 2/101\n",
            "94555/94555 [==============================] - 43s 454us/step - loss: 2.8196\n",
            "\n",
            "Epoch 00002: loss improved from 2.99352 to 2.81961, saving model to quick-02.hdf5\n",
            "Epoch 3/101\n",
            "94555/94555 [==============================] - 43s 451us/step - loss: 2.7472\n",
            "\n",
            "Epoch 00003: loss improved from 2.81961 to 2.74719, saving model to quick-03.hdf5\n",
            "Epoch 4/101\n",
            "94555/94555 [==============================] - 43s 452us/step - loss: 2.6988\n",
            "\n",
            "Epoch 00004: loss improved from 2.74719 to 2.69879, saving model to quick-04.hdf5\n",
            "Epoch 5/101\n",
            "94555/94555 [==============================] - 43s 455us/step - loss: 2.6626\n",
            "\n",
            "Epoch 00005: loss improved from 2.69879 to 2.66260, saving model to quick-05.hdf5\n",
            "Epoch 6/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 2.6343\n",
            "\n",
            "Epoch 00006: loss improved from 2.66260 to 2.63426, saving model to quick-06.hdf5\n",
            "Epoch 7/101\n",
            "94555/94555 [==============================] - 44s 465us/step - loss: 2.6104\n",
            "\n",
            "Epoch 00007: loss improved from 2.63426 to 2.61036, saving model to quick-07.hdf5\n",
            "Epoch 8/101\n",
            "94555/94555 [==============================] - 44s 461us/step - loss: 2.5875\n",
            "\n",
            "Epoch 00008: loss improved from 2.61036 to 2.58751, saving model to quick-08.hdf5\n",
            "Epoch 9/101\n",
            "94555/94555 [==============================] - 43s 454us/step - loss: 2.5662\n",
            "\n",
            "Epoch 00009: loss improved from 2.58751 to 2.56621, saving model to quick-09.hdf5\n",
            "Epoch 10/101\n",
            "94555/94555 [==============================] - 43s 450us/step - loss: 2.5460\n",
            "\n",
            "Epoch 00010: loss improved from 2.56621 to 2.54598, saving model to quick-10.hdf5\n",
            "Epoch 11/101\n",
            "94555/94555 [==============================] - 42s 448us/step - loss: 2.5249\n",
            "\n",
            "Epoch 00011: loss improved from 2.54598 to 2.52493, saving model to quick-11.hdf5\n",
            "Epoch 12/101\n",
            "94555/94555 [==============================] - 42s 447us/step - loss: 2.5062\n",
            "\n",
            "Epoch 00012: loss improved from 2.52493 to 2.50615, saving model to quick-12.hdf5\n",
            "Epoch 13/101\n",
            "94555/94555 [==============================] - 42s 447us/step - loss: 2.4871\n",
            "\n",
            "Epoch 00013: loss improved from 2.50615 to 2.48713, saving model to quick-13.hdf5\n",
            "Epoch 14/101\n",
            "94555/94555 [==============================] - 42s 444us/step - loss: 2.4670\n",
            "\n",
            "Epoch 00014: loss improved from 2.48713 to 2.46705, saving model to quick-14.hdf5\n",
            "Epoch 15/101\n",
            "94555/94555 [==============================] - 42s 444us/step - loss: 2.4503\n",
            "\n",
            "Epoch 00015: loss improved from 2.46705 to 2.45030, saving model to quick-15.hdf5\n",
            "Epoch 16/101\n",
            "94555/94555 [==============================] - 43s 451us/step - loss: 2.4329\n",
            "\n",
            "Epoch 00016: loss improved from 2.45030 to 2.43291, saving model to quick-16.hdf5\n",
            "Epoch 17/101\n",
            "94555/94555 [==============================] - 43s 453us/step - loss: 2.4156\n",
            "\n",
            "Epoch 00017: loss improved from 2.43291 to 2.41556, saving model to quick-17.hdf5\n",
            "Epoch 18/101\n",
            "94555/94555 [==============================] - 43s 454us/step - loss: 2.3970\n",
            "\n",
            "Epoch 00018: loss improved from 2.41556 to 2.39698, saving model to quick-18.hdf5\n",
            "Epoch 19/101\n",
            "94555/94555 [==============================] - 42s 444us/step - loss: 2.3795\n",
            "\n",
            "Epoch 00019: loss improved from 2.39698 to 2.37947, saving model to quick-19.hdf5\n",
            "Epoch 20/101\n",
            "94555/94555 [==============================] - 42s 442us/step - loss: 2.3592\n",
            "\n",
            "Epoch 00020: loss improved from 2.37947 to 2.35921, saving model to quick-20.hdf5\n",
            "Epoch 21/101\n",
            "94555/94555 [==============================] - 42s 443us/step - loss: 2.3423\n",
            "\n",
            "Epoch 00021: loss improved from 2.35921 to 2.34229, saving model to quick-21.hdf5\n",
            "Epoch 22/101\n",
            "94555/94555 [==============================] - 42s 444us/step - loss: 2.3248\n",
            "\n",
            "Epoch 00022: loss improved from 2.34229 to 2.32481, saving model to quick-22.hdf5\n",
            "Epoch 23/101\n",
            "94555/94555 [==============================] - 42s 443us/step - loss: 2.3011\n",
            "\n",
            "Epoch 00023: loss improved from 2.32481 to 2.30108, saving model to quick-23.hdf5\n",
            "Epoch 24/101\n",
            "94555/94555 [==============================] - 42s 443us/step - loss: 2.2811\n",
            "\n",
            "Epoch 00024: loss improved from 2.30108 to 2.28113, saving model to quick-24.hdf5\n",
            "Epoch 25/101\n",
            "94555/94555 [==============================] - 42s 444us/step - loss: 2.2629\n",
            "\n",
            "Epoch 00025: loss improved from 2.28113 to 2.26290, saving model to quick-25.hdf5\n",
            "Epoch 26/101\n",
            "94555/94555 [==============================] - 42s 443us/step - loss: 2.2456\n",
            "\n",
            "Epoch 00026: loss improved from 2.26290 to 2.24555, saving model to quick-26.hdf5\n",
            "Epoch 27/101\n",
            "94555/94555 [==============================] - 42s 446us/step - loss: 2.2253\n",
            "\n",
            "Epoch 00027: loss improved from 2.24555 to 2.22527, saving model to quick-27.hdf5\n",
            "Epoch 28/101\n",
            "94555/94555 [==============================] - 42s 446us/step - loss: 2.2073\n",
            "\n",
            "Epoch 00028: loss improved from 2.22527 to 2.20728, saving model to quick-28.hdf5\n",
            "Epoch 29/101\n",
            "94555/94555 [==============================] - 43s 452us/step - loss: 2.1851\n",
            "\n",
            "Epoch 00029: loss improved from 2.20728 to 2.18507, saving model to quick-29.hdf5\n",
            "Epoch 30/101\n",
            "94555/94555 [==============================] - 43s 455us/step - loss: 2.1681\n",
            "\n",
            "Epoch 00030: loss improved from 2.18507 to 2.16806, saving model to quick-30.hdf5\n",
            "Epoch 31/101\n",
            "94555/94555 [==============================] - 43s 450us/step - loss: 2.1506\n",
            "\n",
            "Epoch 00031: loss improved from 2.16806 to 2.15055, saving model to quick-31.hdf5\n",
            "Epoch 32/101\n",
            "94555/94555 [==============================] - 43s 452us/step - loss: 2.1299\n",
            "\n",
            "Epoch 00032: loss improved from 2.15055 to 2.12986, saving model to quick-32.hdf5\n",
            "Epoch 33/101\n",
            "94555/94555 [==============================] - 43s 457us/step - loss: 2.1134\n",
            "\n",
            "Epoch 00033: loss improved from 2.12986 to 2.11337, saving model to quick-33.hdf5\n",
            "Epoch 34/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 2.0943\n",
            "\n",
            "Epoch 00034: loss improved from 2.11337 to 2.09429, saving model to quick-34.hdf5\n",
            "Epoch 35/101\n",
            "94555/94555 [==============================] - 42s 448us/step - loss: 2.0779\n",
            "\n",
            "Epoch 00035: loss improved from 2.09429 to 2.07792, saving model to quick-35.hdf5\n",
            "Epoch 36/101\n",
            "94555/94555 [==============================] - 45s 478us/step - loss: 2.0618\n",
            "\n",
            "Epoch 00036: loss improved from 2.07792 to 2.06183, saving model to quick-36.hdf5\n",
            "Epoch 37/101\n",
            "94555/94555 [==============================] - 43s 459us/step - loss: 2.0427\n",
            "\n",
            "Epoch 00037: loss improved from 2.06183 to 2.04268, saving model to quick-37.hdf5\n",
            "Epoch 38/101\n",
            "94555/94555 [==============================] - 43s 457us/step - loss: 2.0266\n",
            "\n",
            "Epoch 00038: loss improved from 2.04268 to 2.02656, saving model to quick-38.hdf5\n",
            "Epoch 39/101\n",
            "94555/94555 [==============================] - 44s 467us/step - loss: 2.0089\n",
            "\n",
            "Epoch 00039: loss improved from 2.02656 to 2.00892, saving model to quick-39.hdf5\n",
            "Epoch 40/101\n",
            "94555/94555 [==============================] - 44s 471us/step - loss: 1.9948\n",
            "\n",
            "Epoch 00040: loss improved from 2.00892 to 1.99481, saving model to quick-40.hdf5\n",
            "Epoch 41/101\n",
            "94555/94555 [==============================] - 45s 471us/step - loss: 1.9833\n",
            "\n",
            "Epoch 00041: loss improved from 1.99481 to 1.98334, saving model to quick-41.hdf5\n",
            "Epoch 42/101\n",
            "94555/94555 [==============================] - 44s 463us/step - loss: 1.9646\n",
            "\n",
            "Epoch 00042: loss improved from 1.98334 to 1.96461, saving model to quick-42.hdf5\n",
            "Epoch 43/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 1.9529\n",
            "\n",
            "Epoch 00043: loss improved from 1.96461 to 1.95293, saving model to quick-43.hdf5\n",
            "Epoch 44/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 1.9356\n",
            "\n",
            "Epoch 00044: loss improved from 1.95293 to 1.93560, saving model to quick-44.hdf5\n",
            "Epoch 45/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 1.9259\n",
            "\n",
            "Epoch 00045: loss improved from 1.93560 to 1.92593, saving model to quick-45.hdf5\n",
            "Epoch 46/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 1.9121\n",
            "\n",
            "Epoch 00046: loss improved from 1.92593 to 1.91215, saving model to quick-46.hdf5\n",
            "Epoch 47/101\n",
            "94555/94555 [==============================] - 43s 458us/step - loss: 1.9005\n",
            "\n",
            "Epoch 00047: loss improved from 1.91215 to 1.90050, saving model to quick-47.hdf5\n",
            "Epoch 48/101\n",
            "94555/94555 [==============================] - 44s 461us/step - loss: 1.8828\n",
            "\n",
            "Epoch 00048: loss improved from 1.90050 to 1.88278, saving model to quick-48.hdf5\n",
            "Epoch 49/101\n",
            " 7000/94555 [=>............................] - ETA: 39s - loss: 1.8336"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}