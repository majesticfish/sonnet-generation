{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "huge_rnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "D0JQwBaFhLuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwnZqElShdKh",
        "colab_type": "code",
        "outputId": "4efa2845-1f6c-4a6c-d0e1-dfec1e6e4aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4640
        }
      },
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"shakespeare.txt\"\n",
        "f = open(filename)\n",
        "lines = f.readlines()\n",
        "raw_text = \"\"\n",
        "for line in lines:\n",
        "    if lines == '\\n':\n",
        "        continue\n",
        "    try:\n",
        "        int(line)\n",
        "    except ValueError:\n",
        "        raw_text = raw_text + line\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "# create mapping of unique chars to\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 40\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(500, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(500, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(500))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# define the checkpoint\n",
        "filepath=\"3-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=101, batch_size=100, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  94595\n",
            "Total Vocab:  38\n",
            "Total Patterns:  94555\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 2.8259\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.82592, saving model to 3-weights-improvement-01-2.8259.hdf5\n",
            "Epoch 2/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 2.4280\n",
            "\n",
            "Epoch 00002: loss improved from 2.82592 to 2.42795, saving model to 3-weights-improvement-02-2.4280.hdf5\n",
            "Epoch 3/101\n",
            "94555/94555 [==============================] - 316s 3ms/step - loss: 2.2269\n",
            "\n",
            "Epoch 00003: loss improved from 2.42795 to 2.22689, saving model to 3-weights-improvement-03-2.2269.hdf5\n",
            "Epoch 4/101\n",
            "94555/94555 [==============================] - 316s 3ms/step - loss: 2.0838\n",
            "\n",
            "Epoch 00004: loss improved from 2.22689 to 2.08380, saving model to 3-weights-improvement-04-2.0838.hdf5\n",
            "Epoch 5/101\n",
            "94555/94555 [==============================] - 316s 3ms/step - loss: 1.9710\n",
            "\n",
            "Epoch 00005: loss improved from 2.08380 to 1.97096, saving model to 3-weights-improvement-05-1.9710.hdf5\n",
            "Epoch 6/101\n",
            "94555/94555 [==============================] - 316s 3ms/step - loss: 1.8751\n",
            "\n",
            "Epoch 00006: loss improved from 1.97096 to 1.87507, saving model to 3-weights-improvement-06-1.8751.hdf5\n",
            "Epoch 7/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 1.7943\n",
            "\n",
            "Epoch 00007: loss improved from 1.87507 to 1.79425, saving model to 3-weights-improvement-07-1.7943.hdf5\n",
            "Epoch 8/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 1.7192\n",
            "\n",
            "Epoch 00008: loss improved from 1.79425 to 1.71920, saving model to 3-weights-improvement-08-1.7192.hdf5\n",
            "Epoch 9/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 1.6485\n",
            "\n",
            "Epoch 00009: loss improved from 1.71920 to 1.64854, saving model to 3-weights-improvement-09-1.6485.hdf5\n",
            "Epoch 10/101\n",
            "94555/94555 [==============================] - 320s 3ms/step - loss: 1.5783\n",
            "\n",
            "Epoch 00010: loss improved from 1.64854 to 1.57827, saving model to 3-weights-improvement-10-1.5783.hdf5\n",
            "Epoch 11/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 1.5092\n",
            "\n",
            "Epoch 00011: loss improved from 1.57827 to 1.50924, saving model to 3-weights-improvement-11-1.5092.hdf5\n",
            "Epoch 12/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 1.4449\n",
            "\n",
            "Epoch 00012: loss improved from 1.50924 to 1.44491, saving model to 3-weights-improvement-12-1.4449.hdf5\n",
            "Epoch 13/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 1.3766\n",
            "\n",
            "Epoch 00013: loss improved from 1.44491 to 1.37659, saving model to 3-weights-improvement-13-1.3766.hdf5\n",
            "Epoch 14/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 1.3135\n",
            "\n",
            "Epoch 00014: loss improved from 1.37659 to 1.31351, saving model to 3-weights-improvement-14-1.3135.hdf5\n",
            "Epoch 15/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 1.2483\n",
            "\n",
            "Epoch 00015: loss improved from 1.31351 to 1.24831, saving model to 3-weights-improvement-15-1.2483.hdf5\n",
            "Epoch 16/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 1.1966\n",
            "\n",
            "Epoch 00016: loss improved from 1.24831 to 1.19658, saving model to 3-weights-improvement-16-1.1966.hdf5\n",
            "Epoch 17/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 1.1301\n",
            "\n",
            "Epoch 00017: loss improved from 1.19658 to 1.13011, saving model to 3-weights-improvement-17-1.1301.hdf5\n",
            "Epoch 18/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 1.0773\n",
            "\n",
            "Epoch 00018: loss improved from 1.13011 to 1.07727, saving model to 3-weights-improvement-18-1.0773.hdf5\n",
            "Epoch 19/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 1.0246\n",
            "\n",
            "Epoch 00019: loss improved from 1.07727 to 1.02456, saving model to 3-weights-improvement-19-1.0246.hdf5\n",
            "Epoch 20/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.9733\n",
            "\n",
            "Epoch 00020: loss improved from 1.02456 to 0.97325, saving model to 3-weights-improvement-20-0.9733.hdf5\n",
            "Epoch 21/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.9265\n",
            "\n",
            "Epoch 00021: loss improved from 0.97325 to 0.92649, saving model to 3-weights-improvement-21-0.9265.hdf5\n",
            "Epoch 22/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.8876\n",
            "\n",
            "Epoch 00022: loss improved from 0.92649 to 0.88757, saving model to 3-weights-improvement-22-0.8876.hdf5\n",
            "Epoch 23/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.8425\n",
            "\n",
            "Epoch 00023: loss improved from 0.88757 to 0.84247, saving model to 3-weights-improvement-23-0.8425.hdf5\n",
            "Epoch 24/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.8057\n",
            "\n",
            "Epoch 00024: loss improved from 0.84247 to 0.80572, saving model to 3-weights-improvement-24-0.8057.hdf5\n",
            "Epoch 25/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.7724\n",
            "\n",
            "Epoch 00025: loss improved from 0.80572 to 0.77239, saving model to 3-weights-improvement-25-0.7724.hdf5\n",
            "Epoch 26/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.7487\n",
            "\n",
            "Epoch 00026: loss improved from 0.77239 to 0.74869, saving model to 3-weights-improvement-26-0.7487.hdf5\n",
            "Epoch 27/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.7167\n",
            "\n",
            "Epoch 00027: loss improved from 0.74869 to 0.71671, saving model to 3-weights-improvement-27-0.7167.hdf5\n",
            "Epoch 28/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.6953\n",
            "\n",
            "Epoch 00028: loss improved from 0.71671 to 0.69531, saving model to 3-weights-improvement-28-0.6953.hdf5\n",
            "Epoch 29/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.6720\n",
            "\n",
            "Epoch 00029: loss improved from 0.69531 to 0.67197, saving model to 3-weights-improvement-29-0.6720.hdf5\n",
            "Epoch 30/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.6514\n",
            "\n",
            "Epoch 00030: loss improved from 0.67197 to 0.65140, saving model to 3-weights-improvement-30-0.6514.hdf5\n",
            "Epoch 31/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 0.6339\n",
            "\n",
            "Epoch 00031: loss improved from 0.65140 to 0.63393, saving model to 3-weights-improvement-31-0.6339.hdf5\n",
            "Epoch 32/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.6006\n",
            "\n",
            "Epoch 00032: loss improved from 0.63393 to 0.60061, saving model to 3-weights-improvement-32-0.6006.hdf5\n",
            "Epoch 33/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.6066\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.60061\n",
            "Epoch 34/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.5907\n",
            "\n",
            "Epoch 00034: loss improved from 0.60061 to 0.59070, saving model to 3-weights-improvement-34-0.5907.hdf5\n",
            "Epoch 35/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.5659\n",
            "\n",
            "Epoch 00035: loss improved from 0.59070 to 0.56586, saving model to 3-weights-improvement-35-0.5659.hdf5\n",
            "Epoch 36/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.5605\n",
            "\n",
            "Epoch 00036: loss improved from 0.56586 to 0.56054, saving model to 3-weights-improvement-36-0.5605.hdf5\n",
            "Epoch 37/101\n",
            "94555/94555 [==============================] - 320s 3ms/step - loss: 0.5475\n",
            "\n",
            "Epoch 00037: loss improved from 0.56054 to 0.54752, saving model to 3-weights-improvement-37-0.5475.hdf5\n",
            "Epoch 38/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.5429\n",
            "\n",
            "Epoch 00038: loss improved from 0.54752 to 0.54294, saving model to 3-weights-improvement-38-0.5429.hdf5\n",
            "Epoch 39/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 0.5432\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.54294\n",
            "Epoch 40/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.5308\n",
            "\n",
            "Epoch 00040: loss improved from 0.54294 to 0.53078, saving model to 3-weights-improvement-40-0.5308.hdf5\n",
            "Epoch 41/101\n",
            "94555/94555 [==============================] - 322s 3ms/step - loss: 0.5277\n",
            "\n",
            "Epoch 00041: loss improved from 0.53078 to 0.52771, saving model to 3-weights-improvement-41-0.5277.hdf5\n",
            "Epoch 42/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.5239\n",
            "\n",
            "Epoch 00042: loss improved from 0.52771 to 0.52390, saving model to 3-weights-improvement-42-0.5239.hdf5\n",
            "Epoch 43/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.5108\n",
            "\n",
            "Epoch 00043: loss improved from 0.52390 to 0.51084, saving model to 3-weights-improvement-43-0.5108.hdf5\n",
            "Epoch 44/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 0.5121\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.51084\n",
            "Epoch 45/101\n",
            "94555/94555 [==============================] - 320s 3ms/step - loss: 0.5141\n",
            "\n",
            "Epoch 00045: loss did not improve from 0.51084\n",
            "Epoch 46/101\n",
            "94555/94555 [==============================] - 323s 3ms/step - loss: 0.5028\n",
            "\n",
            "Epoch 00046: loss improved from 0.51084 to 0.50283, saving model to 3-weights-improvement-46-0.5028.hdf5\n",
            "Epoch 47/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.4990\n",
            "\n",
            "Epoch 00047: loss improved from 0.50283 to 0.49898, saving model to 3-weights-improvement-47-0.4990.hdf5\n",
            "Epoch 48/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.4976\n",
            "\n",
            "Epoch 00048: loss improved from 0.49898 to 0.49758, saving model to 3-weights-improvement-48-0.4976.hdf5\n",
            "Epoch 49/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.5024\n",
            "\n",
            "Epoch 00049: loss did not improve from 0.49758\n",
            "Epoch 50/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.4954\n",
            "\n",
            "Epoch 00050: loss improved from 0.49758 to 0.49545, saving model to 3-weights-improvement-50-0.4954.hdf5\n",
            "Epoch 51/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4879\n",
            "\n",
            "Epoch 00051: loss improved from 0.49545 to 0.48786, saving model to 3-weights-improvement-51-0.4879.hdf5\n",
            "Epoch 52/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 0.4892\n",
            "\n",
            "Epoch 00052: loss did not improve from 0.48786\n",
            "Epoch 53/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 0.4944\n",
            "\n",
            "Epoch 00053: loss did not improve from 0.48786\n",
            "Epoch 54/101\n",
            "94555/94555 [==============================] - 316s 3ms/step - loss: 0.5045\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.48786\n",
            "Epoch 55/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 0.4854\n",
            "\n",
            "Epoch 00055: loss improved from 0.48786 to 0.48537, saving model to 3-weights-improvement-55-0.4854.hdf5\n",
            "Epoch 56/101\n",
            "94555/94555 [==============================] - 317s 3ms/step - loss: 0.4931\n",
            "\n",
            "Epoch 00056: loss did not improve from 0.48537\n",
            "Epoch 57/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4870\n",
            "\n",
            "Epoch 00057: loss did not improve from 0.48537\n",
            "Epoch 58/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4912\n",
            "\n",
            "Epoch 00058: loss did not improve from 0.48537\n",
            "Epoch 59/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4874\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.48537\n",
            "Epoch 60/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4898\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.48537\n",
            "Epoch 61/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.4917\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.48537\n",
            "Epoch 62/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.4862\n",
            "\n",
            "Epoch 00062: loss did not improve from 0.48537\n",
            "Epoch 63/101\n",
            "94555/94555 [==============================] - 321s 3ms/step - loss: 0.4837\n",
            "\n",
            "Epoch 00063: loss improved from 0.48537 to 0.48369, saving model to 3-weights-improvement-63-0.4837.hdf5\n",
            "Epoch 64/101\n",
            "94555/94555 [==============================] - 318s 3ms/step - loss: 0.4875\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.48369\n",
            "Epoch 65/101\n",
            "94555/94555 [==============================] - 319s 3ms/step - loss: 0.4870\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.48369\n",
            "Epoch 66/101\n",
            " 8100/94555 [=>............................] - ETA: 4:52 - loss: 0.4644Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}